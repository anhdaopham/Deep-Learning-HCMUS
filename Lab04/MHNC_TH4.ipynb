{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ycCbPEPc14qM"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dF33ZYe-18g8",
    "outputId": "b862d3e7-17b4-4fb3-dea2-d8105ffe029a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.3.0:\n",
      "  Would remove:\n",
      "    /usr/local/bin/estimator_ckpt_converter\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/bin/toco_from_protos\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled tensorflow-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fpklzo1B2Axv",
    "outputId": "ce6c15f0-48df-478d-8dab-95cfee1d7e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0-beta1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
      "\u001b[K     |████████████████████████████████| 87.9MB 33kB/s \n",
      "\u001b[?25hCollecting keras-applications>=1.0.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.33.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.10.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.12.4)\n",
      "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 44.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.35.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.18.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.2)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
      "\u001b[K     |████████████████████████████████| 501kB 38.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta1) (50.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.4.0)\n",
      "Installing collected packages: keras-applications, tb-nightly, tf-estimator-nightly, tensorflow\n",
      "Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.0.0-beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "U56nbV8r2CmI",
    "outputId": "043aed49-5920-48e0-bf54-0f0612400fd0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Label  y\n",
       "0     Go until jurong point, crazy.. Available only ...   ham  0\n",
       "1                         Ok lar... Joking wif u oni...   ham  0\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...  spam  1\n",
       "3     U dun say so early hor... U c already then say...   ham  0\n",
       "4     Nah I don't think he goes to usf, he lives aro...   ham  0\n",
       "...                                                 ...   ... ..\n",
       "5569  This is the 2nd time we have tried 2 contact u...  spam  1\n",
       "5570              Will Ã¼ b going to esplanade fr home?   ham  0\n",
       "5571  Pity, * was in mood for that. So...any other s...   ham  0\n",
       "5572  The guy did some bitching but I acted like i'd...   ham  0\n",
       "5573                         Rofl. Its true to its name   ham  0\n",
       "\n",
       "[5574 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/AML/main/lab-04/spam_detection.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDUWQ7dYtorh",
    "outputId": "f7353694-af92-4605-de2f-13acc2c06fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "['go', 'until', 'jurong', 'point', ',', 'crazy..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'cine', 'there', 'got', 'amore', 'wat', '...']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "texts = df[\"Text\"].to_list()\n",
    "texts = [text.lower() for text in texts ]           # chuyển các đoạn text thành chữ thường (word embedding chỉ cho chữ thường)\n",
    "tokenized_texts = [nltk.tokenize.word_tokenize(text) for text in texts]    # tách câu thành một list các từ\n",
    "\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNant1UrtsDw",
    "outputId": "35a8a192-29c2-4c78-b9a0-a58aa23270a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-17 08:20:45--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2020-11-17 08:20:45--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2020-11-17 08:20:46--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  2.20MB/s    in 6m 31s  \n",
      "\n",
      "2020-11-17 08:27:18 (2.10 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9tQ_oC6uSuX",
    "outputId": "2798c53d-9b4d-4aa4-cdd8-f0508f34b09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "! unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nFwJdMSHWhXK"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "def load_word_embeddings(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    vocab, matrix = [], []\n",
    "    i=0\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        vocab.append(tokens[0])\n",
    "        matrix.append(list(map(float, tokens[1:])))\n",
    "    return vocab, np.asarray(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dF5iXBkWW2JT",
    "outputId": "2eded467-394c-41ec-ac86-c31780797ad3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04656  ,  0.21318  , -0.0074364, ...,  0.0090611, -0.20989  ,\n",
       "         0.053913 ],\n",
       "       [-0.25539  , -0.25723  ,  0.13169  , ..., -0.2329   , -0.12226  ,\n",
       "         0.35499  ],\n",
       "       [-0.12559  ,  0.01363  ,  0.10306  , ..., -0.34224  , -0.022394 ,\n",
       "         0.13684  ],\n",
       "       ...,\n",
       "       [ 0.075713 , -0.040502 ,  0.18345  , ...,  0.21838  ,  0.30967  ,\n",
       "         0.43761  ],\n",
       "       [ 0.81451  , -0.36221  ,  0.31186  , ...,  0.075486 ,  0.28408  ,\n",
       "        -0.17559  ],\n",
       "       [ 0.429191 , -0.296897 ,  0.15011  , ...,  0.28975  ,  0.32618  ,\n",
       "        -0.0590532]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab, matrix = load_word_embeddings(\"glove.6B.300d.txt\")\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QIFIWN4sgmex"
   },
   "outputs": [],
   "source": [
    "## Gán các mã\n",
    "__PADDED_INDEX__ = 0    # mã dùng cho các vị trí chỉ có tính nối dài cho cùng kích thước\n",
    "__UNKNOWN_WORD__ = 1    # mã cho những từ không có trong embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mN_ToMGHgqD6"
   },
   "outputs": [],
   "source": [
    "# Tạo một dictionary, có nhiệm vụ là một ánh xạ từ ảnh sang mã số, mã số được bắt đầu từ 2 vì số 0 và 1 được dành cho trường hợp đặc biệt\n",
    "word_to_index = {word: index+2 for index, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvdEqQQCgr1x",
    "outputId": "9cb7a8fe-3861-4b1c-ba36-2afadcdaa2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.04656    0.21318   -0.0074364 ...  0.0090611 -0.20989    0.053913 ]\n",
      " ...\n",
      " [ 0.075713  -0.040502   0.18345   ...  0.21838    0.30967    0.43761  ]\n",
      " [ 0.81451   -0.36221    0.31186   ...  0.075486   0.28408   -0.17559  ]\n",
      " [ 0.429191  -0.296897   0.15011   ...  0.28975    0.32618   -0.0590532]]\n"
     ]
    }
   ],
   "source": [
    "# Do do mã số được bắt đầu từ 2, nên cần thêm 2 vector vào đàu ma trận\n",
    "embedding_matrix = np.pad(matrix, [[2,0],[0,0]], mode='constant', constant_values =0.0)\n",
    "print(embedding_matrix)\n",
    "\n",
    "# Khi đó, __PADDED_INDEX__ dùng dòng đầu tiên của  embedding_matrix\n",
    "# __UNKNOWN_WORD__ dùng dòng thứ hai của embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WckcHSoHgv5o",
    "outputId": "66e3dea2-f159-418d-bd5e-bc4f0422fdeb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## Bây giờ ta sẽ chuyển data spam dection thành các mã số\n",
    "import tensorflow as tf\n",
    "\n",
    "X = []\n",
    "for text in tokenized_texts:\n",
    "    cur_text_indices = []\n",
    "    for word in text:\n",
    "        if word in word_to_index:\n",
    "            cur_text_indices.append(word_to_index[word])    ## map từ word sang index\n",
    "        else:\n",
    "            cur_text_indices.append(__UNKNOWN_WORD__)       ## gán unknown cho từ không có trong bộ glove\n",
    "    X.append(cur_text_indices)\n",
    "\n",
    "## pad data cho có cùng chiều dài\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(sequences=X,       # sequences: list các câu có độ dài không bằng nhau\n",
    "                                                  padding='post')    # vị trí pad là 'pre' (trước) hoặc 'post' (sau)\n",
    "\n",
    "y = df['y'].values   ## Label của bài toán, 0 là không phải spam, 1 là spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VVYd_qdngzOl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size= 0.2, random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VT7t678j5ka"
   },
   "source": [
    "**Mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYSCIlMNj0XK",
    "outputId": "87458e7f-8967-4e90-dd53-e691e562803f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:3868: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         120000600 \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 120,161,202\n",
      "Trainable params: 160,602\n",
      "Non-trainable params: 120,000,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(None,))                   ## None biểu thị kích thước không xác định của câu\n",
    "\n",
    "embed = Embedding(input_dim=embedding_matrix.shape[0],   ## Khai báo kích thước của vocab\n",
    "                 output_dim=embedding_matrix.shape[1],   ## Khai báo kích thước của embedding\n",
    "                  embeddings_initializer = tf.keras.initializers.Constant(value=embedding_matrix),  ## Khởi tạo cho embedding bằng ma trận có sẵn\n",
    "                  trainable=False,                       ## Không cần thiết train embedding\n",
    "                 mask_zero=True)(inputs)                 ## zero_mask: những vị trí có giá trị 0 không được tính toán, vì đó là giá trị thêm vào cho đủ độ dài mà thôi\n",
    "                                                         ##  (__PADDED_INDEX__ gán bằng 0)\n",
    "\n",
    "lstm = LSTM(units=100,                          ## units: kích thước của hidden_state trong LSTM\n",
    "            return_sequences=False)(embed)      ## return_sequences: LSTM trả về toàn bộ  hay là trả về hidden_state cuối cùng\n",
    "\n",
    "dense = Dense(units=2, activation='softmax')(lstm)\n",
    "model = Model(inputs=inputs,\n",
    "              outputs=dense)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5j-vlm2_kRIY",
    "outputId": "badb4a10-315c-4267-b837-5b55ce90b2a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4459 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4459/4459 [==============================] - 204s 46ms/sample - loss: 0.1455 - accuracy: 0.9442 - val_loss: 0.0701 - val_accuracy: 0.9767\n",
      "Epoch 2/10\n",
      "4459/4459 [==============================] - 202s 45ms/sample - loss: 0.0578 - accuracy: 0.9830 - val_loss: 0.0650 - val_accuracy: 0.9803\n",
      "Epoch 3/10\n",
      "4459/4459 [==============================] - 207s 46ms/sample - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "4459/4459 [==============================] - 212s 48ms/sample - loss: 0.0347 - accuracy: 0.9892 - val_loss: 0.0536 - val_accuracy: 0.9857\n",
      "Epoch 5/10\n",
      "4459/4459 [==============================] - 101s 23ms/sample - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0550 - val_accuracy: 0.9839\n",
      "Epoch 6/10\n",
      "4459/4459 [==============================] - 207s 46ms/sample - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.0523 - val_accuracy: 0.9874\n",
      "Epoch 7/10\n",
      "4459/4459 [==============================] - 101s 23ms/sample - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0575 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "4459/4459 [==============================] - 101s 23ms/sample - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0690 - val_accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "4459/4459 [==============================] - 99s 22ms/sample - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0601 - val_accuracy: 0.9857\n",
      "Epoch 10/10\n",
      "4459/4459 [==============================] - 99s 22ms/sample - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0648 - val_accuracy: 0.9865\n",
      "1115/1115 [==============================] - 10s 9ms/sample - loss: 0.0523 - accuracy: 0.9874\n",
      "Accuracy on valid:  0.9874439\n"
     ]
    }
   ],
   "source": [
    "mc = tf.keras.callbacks.ModelCheckpoint(filepath=\"lstm_spam.h5\", \n",
    "                                     monitor='val_loss',\n",
    "                                     mode='min', \n",
    "                                     verbose=0, \n",
    "                                     save_best_only=True)\n",
    "# Train\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "         epochs=10,\n",
    "         callbacks=[mc])\n",
    "\n",
    "model.load_weights(\"lstm_spam.h5\")\n",
    "_, val_acc = model.evaluate(X_valid, y_valid)\n",
    "print(\"Accuracy on valid: \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Qc1kIJoHgx7O"
   },
   "outputs": [],
   "source": [
    "def compare(arr):\n",
    "  spam = True\n",
    "  if (arr[0][0] > arr[0][1]):\n",
    "    spam = False\n",
    "  return spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "2Fjp6UAhbj_t"
   },
   "outputs": [],
   "source": [
    "def model_predict(text):\n",
    "  text_test = [text.lower()]           # chuyển các đoạn text thành chữ thường \n",
    "  tokenized_text_test = [nltk.tokenize.word_tokenize(text)]    # tách câu thành một list các từ\n",
    "\n",
    "  X_test = []\n",
    "  for text in tokenized_text_test:\n",
    "      cur_text_indices = []\n",
    "      for word in text:\n",
    "          if word in word_to_index:\n",
    "              cur_text_indices.append(word_to_index[word])    ## map từ word sang index\n",
    "          else:\n",
    "              cur_text_indices.append(__UNKNOWN_WORD__)       \n",
    "      X_test.append(cur_text_indices)\n",
    "\n",
    "  ## pad data cho có cùng chiều dài\n",
    "  X_test = tf.keras.preprocessing.sequence.pad_sequences(sequences=X_test,       # sequences: list các câu có độ dài không bằng nhau\n",
    "                                                    padding='post')    # vị trí pad là 'pre' (trước) hoặc 'post' (sau)\n",
    "  #predict\n",
    "  return compare(model.predict(X_test, verbose=0))                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP596HUYgY3E",
    "outputId": "812be141-ff3c-4566-efaf-8b26c3975c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanna ask something? just send me a mess\n",
      "This is not spam\n",
      "Urgent! You have won our competition's prize!! Please call us now.\n",
      "This is spam!\n",
      "Call me to get a free holiday now\n",
      "This is not spam\n"
     ]
    }
   ],
   "source": [
    "text_test = []\n",
    "text_test.append(\"wanna ask something? just send me a mess\")\n",
    "text_test.append(\"Urgent! You have won our competition's prize!! Please call us now.\")\n",
    "text_test.append(\"Call me to get a free holiday now\")\n",
    "\n",
    "for i in range(len(text_test)):\n",
    "  print(text_test[i])\n",
    "  if (model_predict(text_test[i]) == True):\n",
    "    print(\"This is spam!\")\n",
    "  else:\n",
    "    print(\"This is not spam\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MHNC_TH4_1611039.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
